#信息论 

![image.png](https://obsidian-1317758465.cos.ap-shanghai.myqcloud.com/images/20230425230941.png)

- The most important continuous alphabet channel is the Gaussian channel. For example, wireless telephone channels and satellite links
- The noise $Z_i$ is drawn i.i.d. from a Gaussian distribution with variance $N$
- The noise $Z_i$ is assumed to be independent of the signal $X_i$
- <mark style="background: #FFB86CA6;">This is a time-discrete channel with output $Y_i$ at time $i$, where $Y_i$ is the sum of the input $X_i$ and the noise $Z_i$</mark>
$$
Y_i=X_i+Z_i, \quad Z_i \sim \mathcal{N}(0, N)
$$
- <mark style="background: #FF5582A6;">Without further conditions, the capacity of this channel may be $\infty$.</mark>

The values of $X$ may be very sparse

>[!Info] note
>Assume the variance of noise $N$ is neglected compared to the distances of the values of $X$. Then $Y=X+Z \approx X$.  Thus $I(X ; Y) \approx H(X)$, which may be $\infty$.

## Intuition

![image.png](https://obsidian-1317758465.cos.ap-shanghai.myqcloud.com/images/20230425232222.png)

Consider any codeword $x^n$ of length $n$.
$$
Y^n=x^n+Z^n
$$
The received vector is normally distributed with mean equal to the true codeword and variance equal to the noise variance.
- With high probability, the received vector is contained in a sphere of radius $\sqrt{n(N+\epsilon)}$ around the true codeword.
- If we assign everything within this sphere to the given codeword, when this codeword is sent there will be an error only if the received vector falls outside the sphere, which has low probability.

>[!summary]
* Each codeword is represented by a sphere
* Low decoding error requires no intersection between any spheres

![image.png](https://obsidian-1317758465.cos.ap-shanghai.myqcloud.com/images/20230425232822.png)

The received vectors $(Y=X+Z)$ have energy no greater than $n(P+N)$, so they lie in a sphere of radius $\sqrt{n(P+N)}$
- The volume of an $\mathrm{n}$-dimensional sphere is of the form $C_n r^n$, where $r$ is the radius of the sphere.
$$
2 \pi r, \pi r^2 \text { and } \frac{4}{3} \pi r^3
$$
* The volumes are approximated by
$$
C_n(n N)^{\frac{n}{2}} \text { and } C_n(n(P+N))^{\frac{n}{2}}
$$

## Definition


 >A $(M, n)$ code for the Gaussian channel with power constraint $P$ consists of the following:
1. An index set $\{1,2, \ldots, M\}$.
2. An encoding function $x:\{1,2, \ldots, M\} \rightarrow x^n$, yielding codewords $x^n(1), x^n(2), \ldots$, $x^n(M)$, satisfying the power constraint $P$; that is, for every codeword
$$
\sum_{i=1}^n x_i^2(w) \leq n P, \quad w=1,2, \ldots, M
$$
3. A decoding function
$$
g: \mathcal{Y}^n \rightarrow\{1,2, \ldots, M\}
$$

>[!note] 
>The arithmetic average of the probability of error is defined by:
>$$
P_e^{(n)}=\frac{1}{2^{n R}} \sum \lambda_i
>$$

A rate $R$ is said to be achievable for a Gaussian channel with a power constraint $P$ if there exists a sequence of $\left(2^{n R}, n\right)$ codes with codewords satisfying the power constraint such that the maximal probability of error $\lambda^{(n)}$ tends to zero. 
The capacity of the channel is the supremum of the achievable rates. Compared with [[Rate and Capacity]]

