#信息论 

- In probability theory and statistics, the <mark style="background: #FF5582A6;">multivariate normal distribution, multivariate Gaussian distribution, or joint normal distribution</mark> is a generalization of the one dimensional (univariate) normal distribution to higher dimensions.
- More generally, let $\mathcal{N}(\mu, K)$ denote the multivariate Gaussian distribution with mean $\mu$ and covariance matrix $K$, i.e., the joint pdf of the distribution is given by
$$
f(x)=\frac{1}{(\sqrt{2 \pi})^n|K|^{1 / 2}} e^{-\frac{1}{2}(x-\mu)^T K^{-1}(x-\mu)}
$$

- One definition is that a random vector is said to be k-variate normally distributed if every linear combination of its $k$ components has a univariate normal distribution.

## Entropy of multivariate normal distribution

>[!Note] (Entropy of a multivariate normal distribution) 

Let $X_1, X_2, \ldots, X_n$ have a multivariate normal distribution with mean $\mu$ and covariance matrix $K$
$$
h\left(X_1, X_2, \ldots, X_n\right)=h(\mathcal{N}(\mu, K))=\frac{1}{2} \log (2 \pi e)^n|K|
$$
****
$$f(\mathbf{x})=\frac{1}{(\sqrt{2 \pi})^n|K|^{\frac{1}{2}}} e^{-\frac{1}{2}(\mathbf{x}-\mu)^T K^{-1}(\mathbf{x}-\mu)}$$


>[!Note] 
$\begin{aligned} h(f) & =-\int f(\mathbf{x})\left[-\frac{1}{2}(\mathbf{x}-\mu)^T K^{-1}(\mathbf{x}-\mu)-\ln (\sqrt{2 \pi})^n|K|^{\frac{1}{2}}\right] d \mathbf{x} \\ & =\frac{1}{2} E\left[\sum_{i, j}\left(X_i-\mu_i\right)\left(X_j-\mu_j\right)\left(K^{-1}\right)_{i j}\right]+\frac{1}{2} \ln (2 \pi)^n|K| \\ & =\frac{1}{2} \sum_{i, j} E\left[\left(X_j-\mu_j\right)\left(X_i-\mu_i\right)\right]\left(K^{-1}\right)_{i j}+\frac{1}{2} \ln (2 \pi)^n|K| \\ & =\frac{1}{2} \sum_j \sum_i K_{j i}\left(K^{-1}\right)_{i j}+\frac{1}{2} \ln (2 \pi)^n|K| \\ & =\frac{1}{2} \sum_j\left(K K^{-1}\right)_{j j}+\frac{1}{2} \ln (2 \pi)^n|K|\\& =\frac{1}{2} \sum_j I_{j j}+\frac{1}{2} \ln (2 \pi)^n|K| \\ & =\frac{n}{2}+\frac{1}{2} \ln (2 \pi)^n|K| \\ & =\frac{1}{2} \ln (2 \pi e)^n|K| \quad \text { nats } \\ & =\frac{1}{2} \log (2 \pi e)^n|K| \quad \text { bits. }\end{aligned}$
