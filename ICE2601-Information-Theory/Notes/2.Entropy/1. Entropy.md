#信息论 

For a discrete random variable $X$ defined on $\mathcal{X}$,
$$
0 \leq H(X) \leq \log |\mathcal{X}|
$$
When $0 \leq x \leq 1,-x \log x \geq 0 . x \log x=0$ iff $x=0$ or $x=1$
$$
H(X) \geq 0
$$
- By definition, we need to prove $\sum_{x \in X}-p(x) \log p(x) \leq \log |\mathcal{X}|$ Facts:
- <mark style="background: #FF5582A6;">$f(x)=-x \log x$ is concave in $x$</mark>
- $\sum_x p(x)=1$


By applying the concavity of $f(x)$,
$$
\frac{1}{|\mathcal{X}|} \sum_{x \in \mathcal{X}}-p(x) \log p(x) \leq-\frac{1}{|\mathcal{X}|} \log \frac{\sum_x p(x)}{|\mathcal{X}|}=\frac{1}{|\mathcal{X}|} \log |\mathcal{X}|
$$
Equality if and only if $p(x)=1 /|\mathcal{X}|$. (Uniform distribution maximizes entropy)
>Convexity (Concavity) is widely applied:
>$$
>\sum_i p_i f\left(x_i\right) \leq f\left(\sum_i p_i x_i\right)
>$$